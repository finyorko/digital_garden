---
{"type":"default","title":"[[SQLite的锁和原子操作]]","description":null,"aliases":null,"id":null,"author":"fun","category":null,"categories":null,"mathjax":true,"tags":["SQLite"],"date":"2024-04-21","updated":"2024-05-07T19:45:30.020+08:00","comments":true,"publish":true,"dg-publish":true,"permalink":"/02 科研笔记/SQLite/SQLite的锁和原子操作/","dgPassFrontmatter":true,"created":"2024-04-21T21:06:04.932+08:00"}
---


# 简介

本文描述了SQLite的锁机制，并介绍了为保证数据库文件不被损坏而采取的种种手段，对于一些小型应用值得借鉴。

## SQLite中的锁


## SQLite的原子提交

> [!info]+ 官网原子提交介绍
> http://www.sqlite.org/atomiccommit.html
> 
> 本文基于此次提交之后的内容编写：[2022-12-31 21:51:03](https://sqlite.org/docsrc/finfo/pages/atomiccommit.in?m=a727909a51) UTC_

### 简介
  
SQLite等事务型数据库的一个重要特性是“原子提交”。原子提交意味着一个事务内的所有数据库更改要么全部发生，要么一个也不发生。有了原子提交，就好像对数据库文件的不同部分进行的多次写入是在同一时刻同时发生的。实际的硬件会对大容量存储的写入进行串行化，且写入单个扇区需要一定的时间。因此，不可能做到真正同时或瞬时地写入数据库文件的许多不同扇区。但是，SQLite内部的原子提交逻辑使得一个事务的更改看起来好像是即时并且同时写入的。

SQLite具有重要的特性：即使事务被操作系统崩溃或电源故障中断，事务看起来仍然是原子的。

本文描述了SQLite用来创造原子提交（假象/错觉）的技术。

本文中的信息仅适用于SQLite处于“回滚模式”（`rollback mode`）时，换句话说，就是SQLite==**没有**==使用[write-ahead log](https://www.sqlite.org/wal.html)。当启用预写日志时，SQLite仍支持原子提交，但它通过与本文所述不同的机制来实现原子提交。有关SQLite如何在该上下文中支持原子提交的更多信息，请参见[write-ahead log documentation](https://www.sqlite.org/wal.html)。

### 硬件设定

在本文中，我们将把大容量存储设备统称为“磁盘”(`disk`)，尽管这种存储设备实际上可能是闪存。

我们假设磁盘是按块写入的，这些块我们称之为“扇区”（`sector`）。我们没办法直接修改小于一个扇区的磁盘部分。要更改小于一个扇区的磁盘部分，必须读入包含想要更改部分的整个扇区，进行更改，然后再写回整个扇区。

在传统的旋转磁盘上，扇区是读写传输的最小单位。然而，在闪存上，最小读取量通常比最小写入量小得多。SQLite仅关心最小写入量，因此在本文中，当我们说“扇区”时，我们指的是一次性可以**写入**大容量存储的最小数据量。

在SQLite版本3.3.14之前，所有情况下都假定扇区大小为512字节。虽然有一个编译时选项可以更改这一设置，但代码从未在更大值上进行过测试。因为直到不久之前，所有磁盘驱动器内部使用的都是512字节的扇区，所以512字节的扇区假设看起来是合理的。然而，最近有推动增加磁盘扇区大小到4096字节的趋势。此外，闪存的扇区大小通常大于512字节。出于这些原因，从3.3.14版本开始的SQLite版本在操作系统接口层中有一种方法，用于查询底层文件系统以找到真实的扇区大小。在当前实现（版本3.5.0）中，该方法仍返回硬编码值512字节，因为在Unix或Windows上没有标准的方法来发现真实的扇区大小。但该方法可供嵌入式设备制造商根据自己的需要进行调整。而且，我们保留了在未来在Unix和Windows上填充更有意义实现的可能性。

SQLite 并==不==假定扇区写操作是原子的。然而，SQLite 总是假设扇区写入是线性的。所谓“线性”，指的是SQLite 在写入一个扇区时，硬件从数据的一端开始，逐字节写入直到到达另一端。写入可能从头到尾，也可能从尾到头。如果在扇区写入过程中发生掉电故障，可能会导致扇区的一部分被修改而另一部分保持不变。SQLite 的关键设定是：如果扇区的任何部分发生变化，那是它开始的部分发了变化，就是它结束部分发生了变化。因此，硬件永远不会从扇区中间开始写入并向两端进行。我们不知道这个假设是否总是正确的，但它看起来是合理的。

上一段说明了 SQLite **不假设**扇区写操作是原子的。但从 SQLite 版本 3.5.0 开始，有一个新的接口叫做虚拟文件系统[VFS](https://www.sqlite.org/vfs.html)接口。VFS 是 SQLite 与底层文件系统通信的唯一手段。代码默认为 Unix 和 Windows 提供了 VFS 实现，并且可以让用户在运行时实现一个自定义的VFS实现。 VFS 接口中有一个方法叫做 xDeviceCharacteristics，这个方法查询底层文件系统，读取实际的文件系统各种特性。xDeviceCharacteristics可以指明扇区写操作是原子的，如果确实如此，SQLite 肯定会利用这里好处。但是，Unix 和 Windows 的默认 xDeviceCharacteristics 实现并未指明扇区写操作是原子的，因此这些优化通常被忽略掉了。

SQLite 假设操作系统会对写入操作进行缓冲，因此写入请求返回时，有可能数据还没有真实写入到存储中。SQLite 进一步假设写操作会被操作系统重新记录并整理排序。因此，在关键点，SQLite 会执行“flush”或“fsync”操作。SQLite假定flush或fsync在数据没有真实的写入到硬盘之前是不会返回的。但是某些版本的 Windows 和 Linux 上，flush 和 fsync 原语是有问题的，这是不幸的。它使 SQLite 面临在提交过程中发生电源故障后数据库损坏的可能性。然而，SQLite 无法测试或纠正这种情况（因为这是操作系统需要保证的）。所以，SQLite 假设其运行的操作系统能够按照广告中那样飘来那个运行。如果事实并非如此，那么只能希望您不会太频繁地遇到断电了。。。

SQLite 假设当文件空间变大时，新的文件空间原来包含垃圾数据，后来才被填入实际的数据。换句话说，SQLite 假设先修改文件大小，再填充文件内容。这是一个悲观的假设，SQLite 必须做一些额外的工作来确保在文件大小增加和新内容写入之间断电时不会导致数据库损坏。VFS 的 xDeviceCharacteristics 可以指明文件系统是否总是先写入数据再改变文件大小的。（如果想看代码的话，看： SQLITE_IOCAP_SAFE_APPEND 属性）。当 xDeviceCharacteristics 方法指示先写入文件内容再改变文件大小的话，SQLite 可以省去一些过于谨慎的数据库保护步骤，从而减少执行提交所需的磁盘 I/O 量。然而，当前的实现对于默认的 Windows 和 Unix VFS 并没有做出这样的假设。

SQLite 假设从用户进程的角度看文件删除是原子的（操作系统需要保证）。我们的意思是，如果 SQLite 请求删除一个文件，并且在删除操作期间断电，一旦电力恢复，只会有两种情况：一种是文件将完全存在，所有原始内容未经更改；另一种是文件已被完全删除。如果电力恢复后，文件只是部分删除，如果其数据的一部分已被更改或擦除，或者文件已被截断但未完全删除，则很可能会导致数据库损坏（这数据库有用才怪。。）。

SQLite 假设由宇宙射线、热噪声、量子波动、设备驱动程序bug或其他机制引起的位错误的检测和纠正是底层硬件和操作系统的责任。SQLite 不会为了检测损坏或 I/O 错误而向数据库文件添加任何冗余。SQLite 假设它读取的数据与之前写入的数据完全相同。

### 单个文件提交
我们着手观察SQLite在针对一个数据库文件时，为保证一个原子提交所采取的步骤。关于在多个数据库文件之间为防止电源故障损坏数据库及保证提交的原子性所采用的技术及具体的文件格式在下一节进行讨论。

#### 初始状态
当数据库连接第一次打开时，计算机的状态示意图如右图所示。图示中最右侧区域（标记为“Disk”）代表存储在大容量存储设备上的信息。每个矩形代表一个扇区。蓝色代表扇区包含原始数据。中间区域是操作系统的磁盘缓存。在我们的示例开始时，缓存还未被使用，所以这些方框是空的。图示左侧区域表示使用SQLite用户进程的内存内容。数据库连接刚刚打开，尚未读取任何信息，因此用户空间为空。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-0.png)

#### 获取一个读锁
在SQLite可以写入数据库之前，它必须先读取数据库以查看已有的数据。即使只是追加新数据，SQLite仍然需要从“sqlite_schema”表中读取数据库信息，以便它能够解析INSERT语句并找出新信息应该存储在数据库文件的哪个位置。

**为了从数据库文件读数据，首先需要获得一个数据库文件的共享锁。一个“共享”锁允许多个数据库连接同时读。**但是，共享锁会阻止另一个数据库连接在我们读取时对数据库文件进行写。这是必要的，因为如果另一个数据库连接在我们读取数据库文件的同时写入数据库文件，我们可能会在变更之前读取一些数据，在变更之后读取其他数据。这会使得由另一个进程所做的修改操作不是原子的。

注意，共享锁是在操作系统的磁盘缓存上，而不是磁盘本身。文件锁通常只是操作系统内核中的标志。（具体细节取决于特定的操作系统层接口。）因此，如果操作系统崩溃或发生电源故障，锁将立即消失。通常情况下，如果创建锁的进程退出，锁也会消失。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-1.png)

#### 从数据库中读取信息

获得共享锁后，我们可以开始从数据库文件中读取信息。在这种情况下，我们假设系统缓存是空的，所以信息必须先从硬盘读取到操作系统缓存，然后从操作系统缓存传输到用户空间。在后续的读取中，部分或全部信息可能已经存在于操作系统缓存中，因此只需要将信息传输到用户空间。

通常只有数据库文件中的一部分页面被读取。在这个例子中，我们展示了8个页面中的3个被读取。在典型的应用中，一个数据库将有成千上万个页面，而一个查询通常只会涉及这些页面的一小部分。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-2.png)

#### 获取保留锁（Reserved Lock）

在对数据库进行**修改**之前，SQLite 首先在数据库文件上获得一个**“保留”锁**。保留锁与共享锁类似，因为保留锁和共享锁都允许其他进程从数据库文件读取。一个保留锁可以与其他进程的多个共享锁共存。然而，**数据库文件上只能有一个保留锁。因此，一次只能有一个进程试图写入数据库。**

保留锁背后的想法是，它表明一个进程打算在不久的将来修改数据库文件，但还没有开始进行修改。正是因为还没有开始修改，其他进程可以继续从读取数据。但是，不应该有其他进程也开始尝试写入数据库。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-3.png)
#### 生成一个回滚日志文件

**在修改数据库文件之前，SQLite 首先创建一个单独的回滚日志文件（rollback journal file），并在其中写进将被修改的页的原始数据。**回滚日志背后的思想是，它包含将数据库恢复到原始状态所需的所有信息。

回滚日志包含一个小的头部（在图中以绿色显示），记录了数据库文件的原始大小。因此，如果修改导致数据库大小发生变化，我们还是可以知道数据库的原始大小。数据库文件中被修改的页码及他们的内容都被写进了回滚日志文件中。

当创建一个新文件时，大多数桌面操作系统（Windows、Linux、Mac OS X）实际上不会立即将任何内容写入磁盘。此文件还只是存在于操作系统磁盘缓存中。这个文件还不会立即写到存储设备中，一般都会有一些延迟，或者到操作系统相当空闲的时候。用户的对于文件生成感觉是要远远快（先）于其真实的发生磁盘I/O操作。右图中我们用图例说明了这一点，当新的回滚日志文件创建之后，它还只是出现在操作系统缓存中，还没真实在写入到硬盘之上。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-4.png)
  
#### 修改用户空间的数据页

在回滚日志中保存了原始页面内容后，就可以在用户空间中修改这些页面了。每个数据库连接都有自己的用户空间，因此在用户空间中所做的更改只对当前的数据库连接可见。其他数据库连接仍然看到的是操作系统磁盘缓存缓冲区中尚未更改的信息。因此，尽管一个进程正忙于修改数据库（暂时只是修改用户空间），其他进程仍然可以继续读取原始数据到自己的用户空间中。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-5.png)

#### 将回滚日志文件刷到disk中

下一步是将回滚日志文件的内容刷新到硬盘中。这个步骤保证了断电后可以恢复数据。这一步也非常耗时，因为写入硬盘通常是一个很慢的操作。

这一步通常不是简单地将回滚日志刷新到磁盘。在大多数平台上，需要两次单独的flush（或 fsync()）操作。
1. 处理回滚日志的内容部分。
2. 修改回滚日志的头部，以显示回滚日志中的页面数，然后将日志头部flush到磁盘。

为什么要进行这种头部修改和额外刷新的原因，将在本文的后面章节介绍。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-6.png)
  
#### 获取独享锁（Exclusive）

在修改数据库文件本身之前，我们必须获取数据库文件的独享锁。获取排他锁实际上分为两步。首先，SQLite 获得一个未决（pending）锁。然后，然后将未决锁升级为独享锁。

未决锁允许其他已经拥有共享锁的进程继续读取数据库文件。但它阻止别的进程获取新的共享锁。未决锁背后的思想是为了防止由大量读引起的写饥饿。（可能有很多个其他进程试图读取数据库文件。每个进程在开始读取之前都会获取一个共享锁，读取所需的内容，然后释放共享锁。然而，如果有许多不同的进程都从同一个数据库读取，可能会发生新进程总是在上一个进程释放其共享锁之前获得一个新的共享锁。因此，从未有一个时刻是数据库文件上没有共享锁的，因此也就永远没有机会让写入者抢到独享锁。未决锁允许现有的读取者完成他们的读取，同时阻止新的读取者读取。）最终，所有的读取者都读完之后，没有共享锁了，未决锁将能够升级为独享锁。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-7.png)

#### 将变更写入到数据库文件中

一旦持有独享锁，当前就没有进程读取数据库文件了，此时修改数据库文件就是安全的了。通常，这些更改只会发生在操作系统的磁盘缓存中，而不会完全写入到硬盘中。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-8.png)

#### 将变更刷新到Disk

一个附加的flush是很有必要的，这样才能确保所有数据库更改都写入到非易失性存储中。这是一个关键步骤，以确保数据库在断电时不受损坏。然而，由于写入磁盘或闪存的很慢，这一步骤与上面[[02 科研笔记/SQLite/SQLite的锁和原子操作#将回滚日志文件刷到disk中\|#将回滚日志文件刷到disk中]]一起，占用了完成一个SQLite事务提交所需的大部分时间。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-9.png)
#### 删除回滚日志文件

当数据变更已经安全的写入到硬盘之后，回滚日志文件就没有必要存在了，因此可以立即删除（在事务提交瞬间删除）。

如果在删除之前发生电源故障或系统崩溃，则恢复进程（稍后会介绍）会保证数据库文件看起来好像从未发生过任何更改（会将日志文件的内容写回到数据库文件中—即使这个数据库没有发生变化）。如果在回滚日志被删除后发生电源故障或系统崩溃，那么看起来所有更改都已被写入磁盘。因此，SQLite给出了这样的印象：无论回滚日志文件是否存在，都**没有对数据库文件进行更改**或**已完成对数据库文件的全部更改**。因此，SQLite判断数据库文件是否完成了变更是依赖于回滚日志文件是否存在。

删除文件并不是真正的原子操作，但从用户进程的角度看，它似乎是原子的。一个进程总是可以询问操作系统“这个文件是否存在？”并且进程会得到一个“YES”或“NO”的答案。在事务提交过程中发生断电后，SQLite将询问操作系统是否存在回滚日志文件。如果答案是“YES”，那么事务未完成并将被回滚。如果答案是“NO”，那么意味着事务确实已提交。

事务的存在取决于回滚日志文件是否存在，而从用户空间进程的角度看，文件的删除是一个原子操作。因此，事务看起来是一个原子操作。

在许多系统上，删除文件的操作成本很高。作为一种优化，可以配置SQLite将日志文件截断为零字节长度，或者用零覆盖日志文件头部。在任一情况下，结果的日志文件将不再能够回滚，因此事务仍然提交。将文件截断为零长度，就像删除文件一样，被认为是从用户进程的角度看的原子操作。用零覆盖日志的头部不是原子操作，但如果日志的任何部分格式错误，日志将不会回滚。因此，可以说，只要头部被足够改变以使其无效，提交就会发生。通常这发生在头部的第一个字节被归零时。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-A.png)

  
#### 释放锁

提交过程的最后一步是释放独享锁，以便其他进程可以访问数据库文件。

在图中，对于较旧版本的SQLite来说，在释放锁时用户空间中保存的内容就被清空了。但是，较新版本的SQLite会将用户空间的信息保留在内存中，以防在下一个事务开始时再次需要使用这些信息。重用已经在本地内存中的信息，比再次从操作系统磁盘缓存中或硬盘上获取信息成本更低。在重用用户空间中的信息之前，我们必须首先重新获取共享锁，同时必须检查一下，保证没有其他进程**在我们获取共享锁之前**对数据库文件进行了更改。数据库文件的第一页中有一个计数器（相当于数据库版本号），数据库文件每做一次更改，计数器就会加一。我们可以通过检查该计数器来了解是否有其他进程修改了数据库。如果数据库被修改了，就必须清除用户空间缓存并重新读取了。但通常情况下没有进行更改，用户空间缓存可以被重用，从而可以显著提升性能。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/commit-B.png)


### 回滚

原子提交设定应该是瞬间发生的。但上述处理显然需要一定的时间。假设在上述提交操作过程中电脑突然断电。为了维持变更瞬间发生的假象，我们必须“回滚”任何部分变更，并将数据库恢复到事务开始前的状态。
#### 当出现问题时
假设在上述[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更刷新到Disk\|#将变更刷新到Disk]]发生断电，当时数据库更改正在写入磁盘。电力恢复后，情况可能如图所示。我们试图更改数据库文件的三个页面，但只有一个页面成功写入。另一个页面部分写入，第三个页面根本没有写入。

当电力恢复时，回滚日志在磁盘上是完整且未受损的。这是一个关键点。进行[[02 科研笔记/SQLite/SQLite的锁和原子操作#将回滚日志文件刷到disk中\|#将回滚日志文件刷到disk中]]的原因是为了在对数据库文件本身进行任何更改之前，确保回滚日志已经安全、完整地写入到非易失性存储。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-0.png)
#### 热回滚日志 HotRollback Journals

当任何SQLite进程首次尝试访问数据库文件时，获取一个共享锁。但随后它注意到存在一个回滚日志文件。SQLite随后检查回滚日志是否为“hot journal”。**hot journal用来处理数据库，并使数据库恢复到健壮的合理初始状态**。hot journal的存在，代表早期进程在提交事务过程中发生系统崩溃或断电。

回滚日志是“hot”日志如果所有以下条件都成立：

- 回滚日志文件存在。
- 回滚日志非空。
- 主数据库文件上没有保留锁（reserved lock）。
- 回滚日志的头部格式正确，特别是没有被清零。
- 回滚日志文件头部没有包括主日志文件的名字（见下文5.5节）或者包含了主日志文件名称而且主日志文件存在

hot日志的存在表明之前的进程试图提交事务，但在提交完成前由于某种原因中止了。hot日志意味着数据库文件处于不一致状态，并需要在使用之前通过回滚进行修复。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-1.png)

#### 取得数据库的一个独享锁

为了处理“hot”日志文件首先是要取得一个数据库的独享锁。这将防止多个进程在同一时刻来尝试回滚同一个“hot”日志文件。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-2.png)

#### 回滚未完成的变更

一旦进程获得独享锁，它就被允许写入数据库文件。然后，它继续从回滚日志中读取页面的原始内容，并将该内容写回到数据库文件中的原始位置。在中止的事务开始之前，回滚日志的头部已经记录了数据库文件的原始大小。如果之前未完成的事务导致数据库文件变大了，则SQLite使用这些信息将数据库文件截断回其原始大小。在这一步结束时，数据库应该与中止事务开始前的大小和内容相同。

![image.png|](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-3.png)

#### 删除hot日志文件

在回滚日志中的所有信息被回放到数据库文件中（并且在遇到另一次电源故障的情况下被刷新到磁盘，做了flush）之后，就可以删除当前热回滚日志了。

如第3.11节所述，可以不在系统上删除文件，而做出一定的优化，日志文件可能被截断为零长度，或其头部可能被零覆盖。无论哪种方式，此步骤之后，日志不再是hot的。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-4.png)

#### 继续，就像未完成的写操作从未发生过

最后的恢复步骤是将独享锁降级回共享锁。一旦这样做，数据库就回到了被中断的事务开始时的状态。由于所有这些恢复活动完全自动且透明地进行，对于使用SQLite的程序来说，就好像被中断的事务从未发生过一样。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/rollback-5.png)
### 多文件提交

SQLite允许单个数据库连接通过使用[ATTACH DATABASE](http://sqlite.org/lang_attach.html)命令同时与2个或多个数据库文件交互。当单个事务内修改多个数据库文件时，所有文件都会被原子性地更新。换句话说，要么所有数据库文件都被更新，要么一个也不更新。在多个数据库文件中实现原子提交比单个文件更复杂。本节描述了SQLite是如何实现的。

#### 每个数据库的单独回滚日志

当事务涉及多个数据库文件时，每个数据库都有自己的回滚日志文件，每个数据库都是分别加锁的。下图表示，其中一个事务内修改了三个不同的数据库文件。这一步的情况类似于第3.6步中的单文件事务场景。每个数据库文件都有一个保留锁（reserved lock）。对于每个数据库，正在更改的页面的原始内容已被写入该数据库的回滚日志，但日志的内容尚未被刷新到磁盘。目前用户空间的内容可能发生了变化，但是数据库文件本身尚未进行任何更改。

为了简洁，本节中的图表比之前的简化了。蓝色仍然表示原始内容，粉色仍然表示新内容。但是回滚日志和数据库文件中的各个页面没有显示出来，我们也没有区分操作系统缓存中的信息和磁盘上的信息。所有这些因素仍然适用于多文件提交场景。它们只是在图表中占用了很多位置，且没有添加任何新信息，因此在此省略。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-0.png)

#### 主日志文件

多文件提交的下一步是创建一个“主日志”文件。主日志文件的名称与原始数据库文件名相同（使用 [sqlite3_open()](https://www.sqlite.org/c3ref/open.html) 接口打开的数据库，而不是其中一个[附加（ATTACHED）](https://www.sqlite.org/lang_attach.html)的辅助数据库），并在其后附加文本“-mjHHHHHHHH”，其中 HHHHHHHH 是一个随机的32位十六进制数字。每次创建新的主日志文件时，随机的 HHHHHHHH 后缀都会改变。

> [!info] 重要说明
> 上一段中给出的计算主日志文件名的算法是基于SQLite版本3.5.0的实现的。但这不是SQLite规范的一部分，未来版本可能会有变化。

与回滚日志不同，主日志文件不包含任何原始数据库页面内容。主日志文件包含了参与事务的每个数据库的回滚日志的完整路径名。

构建主日志文件后，在采取其他行动之前，会立即flush到硬盘。在Unix系统上，主日志文件所在的目录也会被同步到硬盘，以确保在断电后主日志文件件能够显示在此目录中。

主日志文件的目的是确保在断电时多文件事务的原子性。但是，如果数据库文件有其他设置会影响断电事件中的完整性（如 [PRAGMA synchronous=OFF](https://www.sqlite.org/pragma.html#pragma_synchronous) or [PRAGMA journal_mode=MEMORY](https://www.sqlite.org/pragma.html#pragma_journal_mode)），则创建超级日志会被省略，作为一种优化。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-1.png)
#### 更新回滚日志头部

在每个回滚日志的头部记录主日志文件的完整路径名。在创建回滚日志时，头部已经预留了空间以存放主日志文件名。

在将主日志文件写入回滚日志头部之前和之后，每个回滚日志的内容都会被flush到磁盘。进行这两次flush都非常重要。幸运的是，第二次刷新成本通常较低，因为通常只有日志文件的单页（第一页）发生了变化。

这一步与上述第3.7单文件提交场景中类似。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-2.png)
#### 更新数据库文件

一旦所有回滚日志文件都被刷新到磁盘，就可以安全地开始更新数据库文件了。在写入更改之前，我们必须获取所有数据库文件的独享锁。所有更改写入后，flsuh数据库文件到硬盘是非常重要的，这将防止因系统崩溃或掉电而导致数据库损坏。

这一步对应于之前描述的单文件提交场景中的[[02 科研笔记/SQLite/SQLite的锁和原子操作#获取独享锁（Exclusive）\|#获取独享锁（Exclusive）]]、[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更写入到数据库文件中\|#将变更写入到数据库文件中]]和[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更刷新到Disk\|#将变更刷新到Disk]]。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-3.png)

#### 删除主日志文件

下一步是删除主日志文件。此步骤对应于单文件提交场景中的[[02 科研笔记/SQLite/SQLite的锁和原子操作#删除回滚日志文件\|#删除回滚日志文件]]。

对于多文件事务提交的时刻，需要删除主日志文件。

如果在这一点发生电源故障或操作系统崩溃，即使存在回滚日志，事务也不会在系统重启时回滚。区别在于回滚日志头部的主日志路径名。重启后，SQLite只有在头部没有主日志文件名（这是单文件提交的情况）或主日志文件仍然存在于磁盘上时，才会认为日志是hot的，并做回滚操作（通过将回滚日志文件中的内容放回到数据库文件）。
![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-4.png)
#### 删除回滚日志（多文件提交）

多文件提交的最后一步是删除各个回滚日志，并释放数据库文件上的独享锁，以便其他进程可以看到更改。这对应于单文件提交序列中的[[02 科研笔记/SQLite/SQLite的锁和原子操作#释放锁\|#释放锁]]。

此时事务已经提交，所以删除回滚日志的时间并不关键。当前实现是删除一个回滚日志后，解锁相应的数据库文件，然后再处理下一个回滚日志。但在未来，可能会改变这一做法：删除所有的回滚日志文件之后，释放所有的锁。只要在相应的数据库文件被解锁之前删除了回滚日志，回滚日志被删除的顺序或数据库文件被解锁的顺序就无关紧要。

![image.png](https://amorcode.oss-cn-hangzhou.aliyuncs.com/amor_img/multi-5.png)
### 原子操作的实现细节
上文概述了SQLite中原子提交的工作原理。但它忽略了许多重要的细节。以下小节将尝试填补这些空白。

#### 始终记录完整扇区
当数据库页面的原始内容写入回滚日志时（如[[02 科研笔记/SQLite/SQLite的锁和原子操作#生成一个回滚日志文件\|#生成一个回滚日志文件]]所示），SQLite总是写入一个完整的数据扇区，即使数据库的页面大小小于扇区大小。一直以来，SQLite中的扇区大小一直硬编码为512字节，由于最小页面大小也是512字节，所以这从未成为问题。但从SQLite版本3.3.14开始，SQLite有可能使用扇区大小大于512字节的大容量存储设备。因此，从版本3.3.14开始，只要一个扇区中的任何一页被写进到回滚日志文件中，那么同一扇区中的所有节都会写入到日志文件中去。

为了防止在写入扇区时掉电产生数据库损坏，将扇区内所有页面存储在回滚日志中非常重要。假设页面1、2、3和4都保存在扇区1中，页面2被修改了，为了写入页面2的更改，底层硬件还必须重写页面1、3和4的内容，因为硬件必须以扇区为单元进行写操作。如果这个写操作由于掉电中断，页面1、3或4中的一个或多个页面可能会留下错误的数据（因为实际的物理内存可能发生变化）。因此，为了防止这种损坏，所有这些页面的原始内容必须包含在回滚日志中。

#### 写日志文件时的垃圾数据
当向一个日志文件中追加数据时，SQLite通常持悲观假设，即假定文件变大的部分有垃圾数据，然后再用正确的数据替换掉原来的垃圾数据。换句话说，SQLite假设文件大小首先增加，然后内容再被写入文件。如果在文件大小增加后但在文件内容被写入前发生电源故障，回滚日志可能会包含垃圾数据。如果电源恢复后，另一个SQLite进程看到含有垃圾数据的回滚日志并试图将其回滚到原始数据库文件中，它可能会将一些垃圾复制到数据库文件中，从而损坏数据库文件。

SQLite采用两种防御措施来解决这个问题。
1. 日志文件头部记录页面数量，初始是0。
2. 在同步设置为normal时，为日志文件中的每一页数据生成一个32位的校验和，要验证页是否有效。

首先，SQLite在回滚日志的头部记录回滚日志中的页面数量，这个数字最初是0。因此，在尝试回滚一个不完整（可能已损坏）的回滚日志时，执行回滚的进程会看到日志中包含0个页面，因此不会对数据库做出任何更改。在提交前，回滚日志会被刷新到磁盘，以确保所有内容都已同步到磁盘，文件中没有留下“垃圾”，然后才将头部的页面计数从零更改为回滚日志中真实的页面数量。日志文件的头部总是存放在区别于所有的页数据之外的**独立扇区**中，以此来保证它可被单独修改并且flush，即使发生掉电也不会危及数据页。注意回滚日志会flush两次：一次写入页面数据，第二次写入页面数量到文件头部。

上一段描述了在synchronous pragma设置为“full”时会发生什么。

`PRAGMA synchronous=FULL;` 

默认的synchronous（同步设置）是full，所以通常情况下就是这样。然而，如果将synchronous设置为“normal”，SQLite只会在写入页面数量后flush回滚日志一次。这带来了损坏的风险，因为可能页面数量已经flush到磁盘，但是页面数据还未flush到磁盘。虽然页数据的写入请求会先被发起，但SQLite假定底层的文件系统可能会对写入请求重新排序，所以有可能页面数量会先写到磁盘中，即使是它的写请求在后面。因此，作为第二道防线，SQLite还对回滚日志的每个页面上使用一个32位校验和。在[[02 科研笔记/SQLite/SQLite的锁和原子操作#回滚未完成的变更\|#回滚未完成的变更]]时，需要验证这些页面的校验和。如果看到校验和不对，就会放弃回滚。注意校验和不能保证页面数据是正确的，因为存在一个很小但有限的概率，即使数据已损坏，校验和可能也是正确的。但校验和至少使这种错误不太可能发生。

如果synchronous为FULL，则不需要回滚日志中的校验和。我们只在同步设置为NORMAL时使用校验和。尽管如此，校验和使用时没有坏处的，因此无论synchronous是什么，它们都包含在回滚日志中。


#### 提交前缓存溢出

第3.0节中展示的提交过程假设所有数据库更改在提交前都适合用户的内存大小。这是常见的情况。但有时一个很大的的更改会在事务提交前使用户空间缓存溢出。在这种情况下，在事务完成前，缓存必须写入到数据库中。

在缓存溢出开始时，数据库连接的状态如[[02 科研笔记/SQLite/SQLite的锁和原子操作#修改用户空间的数据页\|#修改用户空间的数据页]]所示。原始页面内容已被保存在回滚日志中，页面的修改存在于用户内存中。为了溢出缓存，SQLite执行这些步骤：[[02 科研笔记/SQLite/SQLite的锁和原子操作# 将回滚日志文件刷到disk中\|# 将回滚日志文件刷到disk中]]，[[02 科研笔记/SQLite/SQLite的锁和原子操作#获取独享锁（Exclusive）\|#获取独享锁（Exclusive）]]，[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更写入到数据库文件中\|#将变更写入到数据库文件中]]。但其余步骤被推迟到事务真正提交时。（可以理解为分多次写，然后回滚日志文件一直加长，最后再一起提交）一个新的日志头部被追加到回滚日志的末尾（在它自己单独的扇区中），此时仍有独享锁，除此之外，处理返回到[[02 科研笔记/SQLite/SQLite的锁和原子操作#修改用户空间的数据页\|#修改用户空间的数据页]]。当事务提交，或者如果发生另一次缓存溢出时，重复执行[[02 科研笔记/SQLite/SQLite的锁和原子操作# 将回滚日志文件刷到disk中\|# 将回滚日志文件刷到disk中]]和[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更写入到数据库文件中\|#将变更写入到数据库文件中]]。（因为第一次操作已经持有独享锁，获取独享锁的过程在第二次和以后过程中被省略。）

缓存溢出导致数据库文件上的锁从保留锁升级为独享锁。这减少了并发性。缓存溢出还导致额外的磁盘flush或fsync操作发生，这些操作是很慢，因此缓存溢出可以严重降低性能。因此，要尽可能避免缓存溢出。

### 优化
性能分析表明，在大多数操作系统系统和大多数情况下，SQLite主要耗时是在磁盘IO上面。因此，减少磁盘I/O的数量就会显著提升SQLite的性能。本节介绍SQLite在保证原子提交的的前提下，为减少磁盘I/O使用的一些技术。

#### 在事务之间保留缓存
提交过程的[[02 科研笔记/SQLite/SQLite的锁和原子操作#释放锁\|#释放锁]]显示，一旦释放了**共享锁**，所有用户空间的数据库内容缓存都必须被丢弃。这样做是因为没有共享锁，其他进程可以自由修改数据库文件内容，因此任何用户空间的数据缓存都可能会过期无效。因此，每个新事务会重新读取以前读取过得数据。这听起来不像看上去那么糟糕，因为被读取的数据很可能仍在操作系统的缓存中。所以“读取”实际上只是从内核空间到用户空间的数据复制。但即便如此，这仍然是需要占用CPU时间的。

从SQLite版本3.3.14开始，增加了一种机制试图减少不必要的数据重新读取。在新版本的SQLite中，当数据库文件上的锁被释放时，用户空间页缓存中的数据被保留。之后，在下一个事务开始时重新获得共享锁后，SQLite会检查是否有其他进程修改了数据库文件。如果自上次释放锁以来数据库以任何方式发生了变化，此时用户空间缓存将被擦除。但通常数据库文件未改变，用户空间缓存可以被保留，并且可以避免一些不必要的读操作。

为了确定数据库文件是否发生了变化，SQLite使用数据库头部（字节24至27）中的一个计数器，每针对数据库做一次修改，就会对此值加一。SQLite在释放数据库锁之前保存此计数器的副本。然后在获得下一个数据库锁后，它将保存的计数器值与当前计数器值进行比较，如果值不同则擦除缓存，如果相同则重用缓存。

  
#### 独享访问模式

SQLite版本3.3.14引入了“独享访问模式”的概念。在独享访问模式下，SQLite在每个事务结束时保留数据库的独享锁。这阻止了其他进程访问数据库，但在许多部署环境中只有单个进程使用数据库，所以这不是一个严重的问题。独享访问模式的优点是可以通过三种方式减少磁盘I/O：
1. 在第一次事务之后的事务中，不需要递增数据库头部的更改计数器。这可以为回滚日志和主数据库文件减少一次页写入。
2. 没有其他进程可以更改数据库，所以在事务开始时永远不需要检查更改计数器并清除用户空间缓存。
3. 每个事务完成后，可以通过用零覆盖回滚日志头部的方式，而不必删除日志文件。这避免了修改日志文件的目录条目，并且避免了释放日志文件对应的的磁盘扇区。此外，下一个事务将重写（overwrite）现有的日志文件内容而不是追加新内容，在大多数系统上，重写比追加快得多。

对于第三个优化，用零覆盖日志文件头部而不是删除回滚日志文件，并不依赖于一直持有一个独享锁。这种优化可以独立于独享锁模式，使用journal_mode pragma设置，如下文第7.6节所述。

#### 不记录空闲列表页面

SQLite数据库的信息被删除之后，这些被删除的数据所使用的页会被加入到空页列表之中。后来的插入操作会尽量先使用空页列表中的页，而不是扩展数据库文件。

一些空闲列表页面包含关键数据；具体来说是其他空闲列表页面的位置。但大多数空闲列表页面不包含有用的信息，这些页面被称为“叶子”页面。我们可以随意修改数据库中叶子空闲列表中页面的内容，而不会影响数据库。

由于叶子空闲列表页面的内容不重要，SQLite在提交过程中避免将空叶子闲列表页面内容存储在回滚日志中。如果一个叶子空闲列表页面发生了变化，并且这个变化在事务恢复期间没有被回滚，数据库不会因此而受到损害。同样，新空闲列表页面的内容在[[02 科研笔记/SQLite/SQLite的锁和原子操作#将变更写入到数据库文件中\|此步]]也不会回写到数据库，也不会[[02 科研笔记/SQLite/SQLite的锁和原子操作#从数据库中读取信息\|#从数据库中读取信息]]。在修改包含有空闲空间的数据库文件时，这些优化可以大大减少磁盘IO操作总数。

#### 单页更新与扇区原子写
从SQLite 3.5.0开始，新的虚拟文件系统（VFS）接口包含一个名为xDeviceCharacteristics的方法，该方法可以读取底层大容量存储设备可能具有的特殊属性。xDeviceCharacteristics可能报告的特殊属性之一是**执行原子性扇区写入的能力**。

回忆一下，默认情况下SQLite假设扇区写入是线性的但不是原子的。线性写入从扇区的一端开始，并逐字节更改信息，直到到达扇区的另一端。如果在线性写入过程中发生掉电，那么扇区的一部分可能被修改，而另一端保持不变。在原子性扇区写入中，要么整个扇区被重写，要么扇区没有任何变化。

我们认为大多数现代磁盘驱动器实现了原子性扇区写入。当断电时，驱动器使用电容中存储的能量或磁盘盘片的角动量来提供的能量，完成当前正在进行的操作。然而，从系统写调用到硬盘驱动器电子设备之间有许多层，因此我们在Unix和w32 VFS实现中采取的比较安全的做法是，假设扇区写入不是原子的。另一方面，对其文件系统有更多控制权的设备制造商可能希望考虑启用xDeviceCharacteristics的原子写入属性，如果他们的硬件确实进行原子写入。

当扇区写入是原子性的，并且数据库的页面大小与扇区大小相同，并且一次数据库的变化只是某一个单独的页发生变化时，SQLite会跳过整个日志记录和同步过程，直接将修改后的页面写入数据库文件。数据库文件第一页中的更改计数器做独立修改，因为即使在更新计数器之前掉电，也不会造成任何数据库损害。

#### 具有安全追加语义的文件系统
SQLite版本3.5.0引入的另一项优化利用了磁盘的“安全追加”行为。回忆一下，SQLite假设当数据被追加到文件中（特别是到回滚日志中）时，文件的大小首先增加，然后内容写入。所以，如果在文件大小增加之后但在内容写入之前电源丢失，文件就会包含无效的“垃圾”数据。然而，VFS的xDeviceCharacteristics方法可能指出文件系统是否实现了“安全追加”语义。这意味着在文件大小增加之前会先写入内容，从而在电源丢失或系统崩溃时，回滚日志中就没有垃圾了。

当文件系统的安全追加语义被指示时，SQLite总是在回滚日志头部为页面计数赋予一个特殊值：-1。页面计数值-1告诉任何试图回滚日志的进程，日志中的页面数应从日志大小**计算**得出。这个-1值从不改变。因此，当提交发生时，我们节省了一次flush操作和日志文件首页的扇区写入操作。此外，当发生缓存溢出时，**我们不再需要在日志末尾追加新的日志头；我们可以简单地继续在现有日志的末尾追加新页面。**

#### 持久化回滚日志
在许多系统上，删除文件是一个很浪费时间的操作。因此，作为一种优化，SQLite可以配置为避免[[02 科研笔记/SQLite/SQLite的锁和原子操作#删除回滚日志文件\|#删除回滚日志文件]]中的删除操作。为了提交事务，不是删除日志文件，而是将文件截断为0字节长度或者用0重写其头部。将文件截断为0长度可以节省必须要对文件的所在目录做的修改（因为文件依旧存在于这个目录中）。重写头部为0还有额外的好处，不必更新文件长度（在许多系统的“inode”中）并且不需要处理新释放的磁盘扇区。此外，在下一个事务中创建日志，将通过重写现有内容而不是在文件末尾追加新内容来完成，重写通常比追加快得多。

SQLite可以通过使用[journal_mode](https://www.sqlite.org/pragma.html#pragma_journal_mode) PRAGMA设置“PERSIST”日志模式，通过用0重写日志头部而不是删除日志文件来提交事务。例如：

```
PRAGMA journal_mode=PERSIST;
```

在许多系统上，使用持久化日志模式可以显著提高性能。当然，缺点是日志文件在事务提交后仍然保留在磁盘上，占用磁盘空间并且可能导致目录杂乱。安全地删除持久化日志文件的唯一方法是在提交事务时将日志模式设置为DELETE：

```
PRAGMA journal_mode=DELETE;
BEGIN EXCLUSIVE;
COMMIT;
```

注意：因为日志文件可能是热的（在使用），如果通过其他方式删除持久化日志文件，会导致对应的数据库文件损坏。

从SQLite版本[version 3.6.4](https://www.sqlite.org/releaselog/3_6_4.html)（2008-10-15）开始，也支持TRUNCATE日志模式：

```
PRAGMA journal_mode=TRUNCATE;
```

在truncate日志模式中，事务是通过将日志文件截断为0长度来提交的，而不是删除日志文件（如DELETE模式）或零化头部（如PERSIST模式）。TRUNCATE模式具有PERSIST模式的优势，即**不需要更新**包含日志文件和数据库的**目录**。因此，截断文件通常比删除文件更快。TRUNCATE的额外优势在于它不会被系统调用（例如fsync()）将更新同步更改到磁盘（当然，如果它这样做会更安全）。但在许多现代文件系统上，截断是一个原子的同步操作，所以我们认为TRUNCATE在面对掉电时通常是安全的。如果您**不确定TRUNCATE操作会在您的文件系统上是否是同步的和原子**的，并且对您来说在断电或者系统崩溃时数据库安全是非常重要的，**那么您需要考虑使用其他的日志模式**。

在具有同步文件系统的嵌入式系统上，TRUNCATE会比PERSIST慢。提交操作的速度相同。但在TRUNCATE之后的后续事务会更慢，因为重写现有内容比追加到文件末尾更快。在TRUNCATE之后，新的日志文件总是使用追加操作，而PERSIST则会使用重写操作。

### 测试原子提交行为
SQLite的开发者对SQLite在面对电源故障及系统崩溃时所拥有健壮性具有足够的自信。因为自动化的测试过程做了大量的面对模拟的电源故障的SQLite恢复能力测试。我们称之为“崩溃测试”。

SQLite中的崩溃测试使用了一个修改过的VFS，它能够模拟种种发生掉电或系统崩溃时文件系统发生的损坏。崩溃测试VFS可以模拟不完整的扇区写入操作、因写入未完成而充满垃圾数据的页面，以及乱序写入，一个测试场景中各种种各样的变化。崩溃测试反复执行事务，让模拟的掉电或系统崩溃发生在不同的各种时刻,造成不同的数据损坏。每次测试之后都会重新打开数据库，验证事务是否完全发生或完全没有发生，并且验证数据库是否处于完全一致的状态。

SQLite中的崩溃测试发现了许多非常微妙的bug（现已修复）。其中一些bug非常隐晦，仅通过代码检查和分析技术不太可能被发现。基于这些测试，SQLite的开发者们相信，任何不使用类似崩溃测试的其他数据库系统可能包含未被发现的bug，在经历系统崩溃或电力故障后，这些bug可能会导致数据库损坏。

### 可能出错的情况
SQLite中的原子提交机制已被证明是健壮的，但它也可能被一些不完整的操作系统实现所陷害。本节描述了几种SQLite数据库可能因电力故障或系统崩溃而损坏的方式。（另见：[How To Corrupt Your Database Files](https://www.sqlite.org/howtocorrupt.html)）

#### 锁的实现错误（Broken Locking Implementations）
SQLite使用文件系统锁确保一次只有一个进程和数据库连接试图修改数据库。文件锁机制在VFS层实现，并且每个操作系统的实现都不同。SQLite依赖于这个实现的正确性。如果在某种情况下，允许两个或多个进程同时写入同一数据库文件，可能会造成严重损坏。

我们收到了有关Windows网络文件系统和NFS的锁实现微妙缺陷的报告。我们无法验证这些报告，但由于在网络文件系统上正确实现锁非常困难，我们没有理由怀疑它们。**建议您避免首先在网络文件系统上使用SQLite，因为性能会很慢**。但如果您必须使用网络文件系统存储SQLite数据库文件，考虑使用其他的锁机制，即使本地文件系统的锁机制出现故障，也可以防止同时对同一数据库进行写入。

苹果MacOSX预装的SQLite版本已经扩展拥有一种可供选择的锁策略可以工作在苹果支持的所有网络文件系统上。只要所有进程以相同方式访问数据库文件，苹果使用的这些扩展就能很好地工作。不幸的是，这些锁定机制并不相互排斥，因此如果一个进程使用AFP锁定访问文件，而另一个进程（可能在不同的机器上）使用dot-file锁，那么两个进程可能会发生冲突，因为AFP锁定不排斥dot-file锁，反之亦然。

#### 不完整的磁盘刷新
SQLite在Unix上使用fsync()系统调用，在win32上使用FlushFileBuffers()系统调用来同步文件系统缓冲区到磁盘中，如第3.7步和第3.10步所示。不幸的是，我们收到报告称，这些接口在许多系统可能不会完美地工作。我们听说在某些Windows版本上可以通过修改注册表完全禁用FlushFileBuffers()。我们也被告知，一些历史版本的Linux，他们的一些文件系统中的fsync()版本是空操作。即使在声称FlushFileBuffers()和fsync()工作正常的系统上，IDE硬盘经常会撒谎说数据已经写入到盘片中，其实还只是存在状态可变的磁盘控制器缓存（易失性存储）中。

在Mac上，你可以设置这个pragma：

```
PRAGMA fullfsync=ON;
```
在Mac上设置fullfsync将保证数据真实的写入到盘片中。但是fullfsync会导致重置磁盘控制器。这并不是一般意义上的慢，它还会导致其他磁盘IO降速。所以不建议使用此配置。

#### 部分文件删除
SQLite假设文件删除是从用户进程的角度看是一个**原子操作**。如果在文件删除过程中发生掉电，那么电源恢复后SQLite希望看到的是完整文件要么完整的存在，要么根本找不到了。**如果操作系统不能做到这一点（原子删除操作），那事务就可能不是原子性的了。**

#### 文件中的垃圾数据
SQLite数据库文件是普通的磁盘文件，可以被普通用户进程打开和读写。一个恶意进程可以打开一个SQLite数据库文件并写入一些损坏的数据。这些损坏的数据也可能由操作系统bug（特别是由断电触发的错误）引起而写入到SQLite数据库中。SQLite面对这种问题无能为力。

#### 删除或重命名hot日志
如果发生操作系统崩溃或断电，并且hot日志留在磁盘上。实际上，在一个SQLite进程打开并回滚数据库文件时，至关重要的是原来的数据库文件和留下来的hot日志（并保留其原始名称）。在[[02 科研笔记/SQLite/SQLite的锁和原子操作#热回滚日志 HotRollback Journals\|#热回滚日志 HotRollback Journals]]的恢复过程中，SQLite在被打开的数据库文件同一目录下去寻找hot日志（文件的名称是由被打开的数据库文件的名称派生的）。如果原始数据库文件或hot日志被移动或重命名，那么将不会看到hot日志，数据库也不会被回滚，数据库可能就会损坏，无法使用了。

我们怀疑SQLite恢复失败的一个常见例子是这样的：断电了，然后电源恢复后，一个好心的用户或系统管理员开始在磁盘上查找磁盘损坏。他们看到数据库文件名为“important.data”，这个文件对他们可能很熟悉。但在崩溃后，还有一个名为“important.data-journal”的热日志。然后用户删除了该hot日志，他认为他在清理系统（怎么会这么干呢？？数据都没啦。。）。我们不知道除了用户培训之外还有什么办法可以阻止这种情况。

如果有多个链接（硬链接或符号链接）指向一个数据库文件，日志将使用通过其打开文件的**链接**的名称创建。如果系统发生崩溃并且数据库再次通过不同的链接打开，将无法定位hot日志，也不会进行回滚。

有时候电力故障会导致文件系统损坏，如最新修改的文件名找不到了，文件被移动到“/lost+found”目录中。当这种情况发生时，将找不到hot日志，也不会进行恢复。SQLite尝试在同步日志文件本身的同时，打开并同步包含回滚日志的目录，来防止这种情况。然而，文件被移动到/lost+found可能由**不相关的进程**在数据库文件目录中**创建与数据库文件同名的文件**引起的。由于这是SQLite无法控制的，SQLite无法防止这种情况。如果您在一个易受此类文件系统命名空间损坏影响的系统上运行（我们相信，大多数现代的日志文件系统都是免疫的），那么你最好把每一个SQLite的数据文件放在你私有的子目录中。

### 未来方向和结论
即使到了现在，还是有人发现了一些关于原子提交机制失败模式，开发者不得不为此做一些补丁。这种情况发生的频率越来越低，可能造成失败的原因也越来越隐蔽。但是，假设SQLite的原子提交逻辑完全没有错误仍然是不明智的。开发者承诺将尽可能快的修复被发现的bug。

开发者们也在寻找优化提交机制的新方法。目前针对Unix（Linux和Mac OS X）及Windows的VFS实现对这些系统的行为做了悲观假设。在与这些系统的专家咨询后，我们可能能够放宽对这些系统的一些假设，使它们运行得更快。特别是，我们怀疑大多数现代文件系统展现出安全追加的特性，并且很多可能已经支持原子性扇区写入。但是在不保证以上特性实现的情况下，SQLite还是会采取保守的方法，做最坏的打算。

 