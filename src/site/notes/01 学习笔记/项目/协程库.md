---
{"type":"project","title":"[[协程库]]","description":null,"aliases":null,"id":null,"author":"fun","category":null,"categories":null,"mathjax":true,"tags":["协程库"],"date":"2024-05-03","updated":"2024-05-07T12:44:10.871+08:00","comments":true,"publish":true,"dg-publish":true,"permalink":"/01 学习笔记/项目/协程库/","dgPassFrontmatter":true,"created":"2024-05-03T16:31:47.493+08:00"}
---

# 参考


> [!info] 感谢各位大佬
> https://github.com/Tencent/libco  
> https://github.com/chenyahui/AnnotatedCode
> https://www.cyhone.com/
> 
> [知乎：为什么协程是趋势](https://www.zhihu.com/question/32218874/answer/216801915)

# 协程介绍

[协程的好处有哪些？ - 腾讯技术工程的回答 - 知乎](https://www.zhihu.com/question/20511233/answer/2743607300)

可以简单的理解为：协程就是用户态的线程，但是上下文切换的时机是靠调用方（也就是写代码的开发人员）自身去控制的。

“其实不应该把协程和多线程做类比，协程更多的是取代异步状态机的数据结构，如果明确这点，就能够清晰使用场景了。”
# 云风 coroutine 协程库源码分析
> **本文作者：** cyhone  
> **本文链接：** [https://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/](https://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/ "云风 coroutine 协程库源码分析")  
> **版权声明：** 本博客所有文章除特别声明外，均采用 [BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/) 许可协议。转载请注明出处！


随着 Golang 的兴起，协程尤其是有栈协程 (stackful coroutine) 越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。

云风实现了一套 [C 语言的协程库](https://github.com/cloudwu/coroutine/)，整体背景可以参考其 [博客](https://blog.codingnow.com/2012/07/c_coroutine.html)。

这个协程库非常轻量级，一共也才 200 多行代码，使用上更贴近于 lua 的写法（众所周知，云风是知名的 lua 粉)。整体基于 ucontext 和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。

同时，我也提供了 [coroutine 注释版](https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine)，辅助大家理解 coroutine 的代码。

## 协程的背景

协程主要有两大优点：

1. 相比线程更加轻量级
    - 线程的创建和调度都是在内核态，而协程是在用户态完成的
    - 线程的个数往往受限于 CPU 核数，线程过多，会造成大量的核间切换。而协程无需考虑这些
2. 将异步流程同步化处理：此问题在知乎上有非常多的 [经典回答](https://www.zhihu.com/question/32218874/answer/216801915)。尤其在 RPC 中进行多服务并发协作的时候，相比于回调式的做法，协程的好处更加明显。这个对于后端程序员的意义更大，非常解放生产力。这里就不再赘述了。

微信基于 c++ 实现的协程库 [libco](https://github.com/Tencent/libco/)，hook 了网络 IO 所需要大部分的系统函数，实现了当 IO 阻塞时协程的自动切换。关于libco的实现细节，可以阅读我的另外一篇文章: [《微信 libco 协程库源码分析》](https://www.cyhone.com/articles/analysis-of-libco/)。

而 Golang 做的则更加极致，直接将协程和自动切换的概念集成进了语言。

协程再细分可以分为有栈协程和无栈协程。我们今天讲的云风的 coroutine，包括微信的 libco、Goroutine，都是属于有栈协程。无栈协程包括 ES6 中的 await/async、Python 中的协程等 以及 [C++20 中的Coroutine](https://en.cppreference.com/w/cpp/language/coroutines)。两种协程实现原理有很大的不同，本文主要基于云风的 coroutine 对有栈协程的原理进行详细的分析。

## 有栈协程的原理

一个程序要真正运行起来，需要两个因素：可执行代码段、数据。体现在 CPU 中，主要包含以下几个方面：

1. EIP 寄存器：用来存储 CPU 要读取指令的地址
2. ESP 寄存器：指向当前线程栈的栈顶位置
3. 其他通用寄存器的内容：包括代表函数参数的 rdi、rsi 等等。
4. 线程栈中的内存内容。

这些数据内容，我们一般将其称为 “上下文” 或者 “现场”。

有栈协程的原理，就是从线程的上下文下手，如果把线程的上下文完全改变。即：改变 EIP 寄存的内容，指向其他指令地址；改变线程栈的内存内容等等。  
这样的话，当前线程运行的程序也就完全改变了，是一个全新的程序。

Linux 下提供了一套函数，叫做 ucontext 簇函数，可以用来获取和设置当前线程的上下文内容。这也是 coroutine 的核心方法。

## coroutine 的使用

我们首先基于 coroutine 的例子来讲下 coroutine 的基本使用，以方便后面原理的讲解

```c
struct args {
	int n;
};

static void foo(struct schedule * S, void *ud) {
	struct args * arg = ud;
	int start = arg->n;
	int i;
	for (i=0;i<5;i++) {
		printf("coroutine %d : %d\n",coroutine_running(S) , start + i);
		// 切出当前协程
		coroutine_yield(S);
	}
}

static void test(struct schedule *S) {
	struct args arg1 = {0};
	struct args arg2 = {100};

	// 创建两个协程
	int co1 = coroutine_new(S, foo, &arg1);
	int co2 = coroutine_new(S, foo, &arg2);

	printf("main start\n");
	while (coroutine_status(S,co1) && coroutine_status(S,co2)) {
		// 使用协程 co1
		coroutine_resume(S,co1);
		// 使用协程 co2
		coroutine_resume(S,co2);
	}
	printf("main end\n");
}

int main() {
	// 创建一个协程调度器
	struct schedule * S = coroutine_open();

	test(S);

	// 关闭协程调度器
	coroutine_close(S);

	return 0;
}
```

从代码看来，首先利用 `coroutine_open` 创建了协程调度器 S，用来统一管理全部的协程。  
同时在 test 函数中，创建了两个协程 co1 和 co2，不断的反复 yield 和 resume 协程，直至两个协程执行完毕。

可以看出，最核心的几个对象和函数是:

1. `struct schedule* S` 协程调度器
2. `coroutine_resume(S,co1);` 切入该协程
3. `coroutine_yield(S);` 切出该协程

接下来，会从这几点出发，分析 coroutine 的原理。建议大家在阅读下文时，同时对照我做的 [coroutine 注释版](https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine)。

## struct schedule 协程调度器

```c
struct schedule {
	char stack[STACK_SIZE];	// 运行时栈，此栈即是共享栈

	ucontext_t main; // 主协程的上下文
	int nco;        // 当前存活的协程个数
	int cap;        // 协程管理器的当前最大容量，即可以同时支持多少个协程。如果不够了，则进行 2 倍扩容
	int running;    // 正在运行的协程 ID
	struct coroutine **co; // 一个一维数组，用于存放所有协程。其长度等于 cap
};
```

协程调度器 schedule 负责管理所有协程，有几个属性非常重要：

1. `struct coroutine **co;` 是一个一维数组，存放了目前所有的协程。
2. `ucontext_t main;` 主协程的上下文，方便后面协程执行完后切回到主协程。
3. `char stack[STACK_SIZE];` 这个非常重要，是所有协程的运行时栈。具体共享栈的原理会在下文讲到。

此外，`coroutine_open` 负责创建并初始化一个协程调度器，`coroutine_close` 负责销毁协程调度器以及清理其管理的所有协程。

## 协程的创建: coroutine_new

```java
struct coroutine {
	coroutine_func func; // 协程所用的函数
	void *ud;  // 协程参数
	ucontext_t ctx; // 协程上下文
	struct schedule * sch; // 该协程所属的调度器
	ptrdiff_t cap; 	 // 已经分配的内存大小
	ptrdiff_t size; // 当前协程运行时栈，保存起来后的大小
	int status;	// 协程当前的状态
	char *stack; // 当前协程的保存起来的运行时栈
};
```

`coroutine_new` 负责创建并初始化一个新协程对象，同时将该协程对象放到协程调度器里面。

这里的实现有两个非常有意思的点：

1. **扩容**：当目前尚存活的线程个数 `nco` 已经等于协程调度器的容量 `cap` 了，这个时候需要对协程调度器进行扩容，这里直接就是非常经典简单的 2 倍扩容。
2. **如果无需扩容，则需要找到一个空的位置，放置初始化好的协程**。这里一般直接从数组第一位开始找，直到找到空的位置即可。但是云风把这里处理成从第 `nco` 位开始寻找（`nco` 代表当前存活的个数。因为一般来说，前面几位最开始都是存活的，从第 `nco` 位开始找，效率会更高。

这样，一个协程对象就被创建好，此时该协程的状态是 `READY`，但尚未正式执行。

`coroutine_resume` 函数会切入到指定协程中执行。当前正在执行的协程的上下文会被保存起来，同时上下文替换成新的协程，该协程的状态将被置为 `RUNNING`。

进入 `coroutine_resume` 函数的前置状态有两个 `READY` 和 `SUSPEND`，这两个状态下 `coroutine_resume` 的处理方法也是有很大不同。我们先看下协程在 READY 状态下进行 `coroutine_resume` 的流程。

## coroutine_resume(READY -> RUNNING）

这块代码比较短，但是非常重要，所以我就直接贴代码了：

```java
// 初始化 ucontext_t 结构体，将当前的上下文放到 C->ctx 里面
getcontext(&C->ctx);
// 将当前协程的运行时栈的栈顶设置为 S->stack，每个协程都这么设置，这就是所谓的共享栈。（注意，这里是栈顶）
C->ctx.uc_stack.ss_sp = S->stack;
C->ctx.uc_stack.ss_size = STACK_SIZE;
C->ctx.uc_link = &S->main;
S->running = id;
C->status = COROUTINE_RUNNING;

// 设置执行 C->ctx 函数, 并将 S 作为参数传进去
uintptr_t ptr = (uintptr_t)S;
makecontext(&C->ctx, (void (*)(void)) mainfunc, 2, (uint32_t)ptr, (uint32_t)(ptr>>32));

// 将当前的上下文放入 S->main 中，并将 C->ctx 的上下文替换到当前上下文
swapcontext(&S->main, &C->ctx);
```

这段函数非常的重要，有几个不可忽视的点：

1. `getcontext(&C->ctx);` 初始化 ucontext_t 结构体，将当前的上下文放到 C->ctx 里面
2. `C->ctx.uc_stack.ss_sp = S->stack;` 设置当前协程的运行时栈，也是共享栈。
3. `C->ctx.uc_link = &S->main;` 如果协程执行完，则切换到 `S->main` 主协程中进行执行。如果不设置, 则默认为 NULL，那么协程执行完，整个程序就结束了。

接下来是 makecontext，这个函数用来设置对应 ucontext 的执行函数。如上，将 `C->ctx` 的执行函数体设置为了 mainfunc。

makecontext 后面的两个参数也非常有意思，这个可以看出来是把一个指针掰成了两个 int 作为参数传给 mainfunc 了。而在 mainfunc 的实现可以看出来，又会把这两个 int 拼成了一个 `struct schedule*`。

那么，为什么不直接传 `struct schedule*` 呢，而要这么做，通过先拆两半，再在函数中拼起来？

这是因为 makecontext 的函数指针的参数是 `uint32_t` 类型，在 64 位系统下，一个 `uint32_t` 没法承载一个指针, 所以基于兼容性的考虑，才采用了这种做法。

接下来调用了 `swapcontext` 函数，这个函数比较简单，但也非常核心。作用是将当前的上下文内容放入 `S->main` 中，并将 `C->ctx` 的上下文替换到当前上下文。这样的话，将会执行新的上下文对应的程序了。在 coroutine 中, 也就是开始执行 `mainfunc` 这个函数。(`mainfunc` 是对用户提供的协程函数的封装)。

## 协程的切出：coroutine_yield

调用 `coroutine_yield` 可以使当前正在运行的协程切换到主协程中运行。此时，该协程会进入 `SUSPEND` 状态

`coroutine_yield` 的具体实现依赖于两个行为：

1. 调用 `_save_stack` 将当前协程的栈保存起来。因为 coroutine 是基于共享栈的，所以协程的栈内容需要单独保存起来。
2. `swapcontext` 将当前上下文保存到当前协程的 ucontext 里面，同时替换当前上下文为主协程的上下文。 这样的话，当前协程会被挂起，主协程会被继续执行。

这里也有个点极其关键, 就是如何保存当前协程的运行时栈, 也就是如何获取整个栈的内存空间。

这里我们需要了解下栈内存空间的布局，即栈的生长方向是从高地址往低地址。我们只要找到栈的栈顶和栈底的地址，就可以找到整个栈内存空间了。

在 coroutine 中，因为协程的运行时栈的内存空间是自己分配的。在 coroutine_resume 阶段设置了 `C->ctx.uc_stack.ss_sp = S.S->stack`。根据以上理论，栈的生长方向是高地址到低地址，因此栈底的就是内存地址最大的位置，即 `S->stack + STACK_SIZE` 就是栈底位置。

那么，如何找到栈顶的位置呢？coroutine 是基于以下方法做的：

```c
void _save_stack(C,S->stack + STACK_SIZE);

static void _save_stack(struct coroutine *C, char *top) {
	char dummy = 0;
	assert(top - &dummy <= STACK_SIZE);
    // 如果已分配内存小于当前栈的大小，则释放内存重新分配
	if (C->cap < top - &dummy) {
		free(C->stack);
		C->cap = top-&dummy;
		C->stack = malloc(C->cap);
	}
	C->size = top - &dummy;
    // 从 dummy 拷贝 size 内存到 C->stack
	memcpy(C->stack, &dummy, C->size);
}
```

这里特意用到了一个 dummy 变量，这个 dummy 的作用非常关键也非常巧妙，大家可以细细体会下。因为 dummy 变量是刚刚分配到栈上的，此时就位于 **栈的最顶部位置**。整个内存布局如下图所示：  
![](https://www.cyhone.com/img/coroutine/coroutine_dummy.png)

因此整个栈的大小就是从栈底到栈顶，`S->stack + STACK_SIZE - &dummy`。

最后又调用了 memcpy 将当前运行时栈的内容，拷贝到了 `C->stack` 中保存了起来。

## coroutine_resume(SUSPEND -> RUNNING）

当协程被 yield 之后会进入 `SUSPEND` 阶段，对该协程调用 `coroutine_resume` 会再次切入该协程。

这里的实现有两个重要的点：

1. `memcpy(S->stack + STACK_SIZE - C->size, C->stack, C->size);`  
    我们知道，在 yield 的时候，协程的栈内容保存到了 C->stack 数组中。  
    这个时候，就是用 memcpy 把协程的之前保存的栈内容，重新拷贝到运行时栈里面。这里有个点，拷贝的开始位置，需要简单计算下  
    `S->stack + STACK_SIZE - C->size` 这个位置就是之前协程的栈顶位置。
    
2. `swapcontext(&S->main, &C->ctx);` 交换上下文。这点在上文有具体描述。
    

## 状态机转换

在 coroutine 中协程定义了四种状态，整个运行期间，也是根据这四种状态进行轮转。

![协程状态机](https://www.cyhone.com/img/coroutine/coroutine-state-machine.png)

## 共享栈

共享栈这个词在 libco 中提到的多，其实 coroutine 也是用的共享栈模型。  
共享栈这个东西说起来很玄乎，实际原理不复杂，本质就是所有的协程在运行的时候都使用同一个栈空间。

有共享栈自然就有非共享栈，也就是每个协程的栈空间都是独立的，固定大小。好处是协程切换的时候，内存不用拷贝来拷贝去。坏处则是 **内存空间浪费**.

因为栈空间在运行时不能随时扩容，否则**如果有指针操作执行了栈内存，扩容后将导致指针失效**。为了防止栈内存不够，每个协程都要预先开一个足够的栈空间使用。当然很多协程在实际运行中也用不了这么大的空间，就必然造成内存的浪费和开辟大内存造成的性能损耗。

共享栈则是提前开了一个足够大的栈空间 (coroutine 默认是 1M)。所有的栈运行的时候，都使用这个栈空间。  
conroutine 是这么设置每个协程的运行时栈：

```c
C->ctx.uc_stack.ss_sp = S->stack;
C->ctx.uc_stack.ss_size = STACK_SIZE;
```

对协程调用 yield 的时候，该协程栈内容暂时保存起来，保存的时候需要用到多少内存就开多少，这样就减少了内存的浪费。(即_save_stack 函数的内容)。  
当 resume 该协程的时候，协程之前保存的栈内容，会被重新拷贝到运行时栈中。

这就是所谓的共享栈的原理。

## 总结

云风的协程库代码非常简约，可以帮助我们更好的理解协程实现的基本原理。但个人觉得这个协程库更像是个原型实现，很多地方在实际开发中并不足够好用。而微信的libco协程库利用系统hook，实现了协程的自动切换，更方便于工业级使用，用法也非常强大。具体可以参考我的另外一篇文章： [《微信 libco 协程库源码分析》](https://www.cyhone.com/articles/analysis-of-libco/)。

参考

- [ucontext 簇函数学习](https://github.com/zfengzhen/Blog/blob/master/article/ucontext%E7%B0%87%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0.md)
- [为什么觉得协程是趋势?](https://www.zhihu.com/question/32218874)
- [天涯明月刀 - 无栈协程的应用](https://gameinstitute.qq.com/community/detail/107515)
- [ucontext 函数族的使用及协程库的实现](https://zhengyinyong.com/ucontext-usage-and-coroutine.html)
- [C++ 协程实现及原理](https://langzi989.github.io/tags/ucontext-t/)
- [腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么?](https://www.zhihu.com/question/52193579/answer/129597362)
- [基于云风协程库的协程原理解读](https://blog.csdn.net/u011228889/article/details/79759834)
- [x86-64 下函数调用及栈帧原理](https://zhuanlan.zhihu.com/p/27339191)

libco 是微信后台开发和使用的协程库，同时也是极少数的直接将 C/C++ 协程运用到如此大规模的生产环境中的案例。

在 [《云风 coroutine 协程库源码分析》](http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/) 中，介绍了有栈协程的实现原理。相比云风的 coroutine，libco 在性能上号称可以调度千万级协程。 从使用上来说，libco 不仅提供了一套类 pthread 的协程通信机制，同时可以零改造地将三方库的阻塞 IO 调用进行协程化。

本文将从源码角度着重分析 libco 的高效之道。

在正式阅读本文之前，如果对有栈协程的实现原理不是特别了解，建议提前阅读 [《云风 coroutine 协程库源码分析》](http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/)。

同时，我也提供了 [libco 注释版](https://github.com/chenyahui/AnnotatedCode/tree/master/libco)，用以辅助理解 libco 的源码

# 微信 libco 协程库源码分析

> **本文作者：** cyhone  
> **本文链接：** [https://www.cyhone.com/articles/analysis-of-libco/](https://www.cyhone.com/articles/analysis-of-libco/ "微信 libco 协程库源码分析")
> **版权声明：** 本博客所有文章除特别声明外，均采用 [BY-NC-SA](https://creativecommons.org/licenses/by-nc-sa/4.0/) 许可协议。转载请注明出处！
## libco 和 coroutine 的基本差异

相比于云风的 coroutine 协程库, libco 整体更成熟，性能更高，使用上也更加方便。主要体现在以下几个方面：

1. 协程上下文切换性能更好
2. 协程在 IO 阻塞时可自动切换，包括 gethostname、mysqlclient 等。
3. 协程可以嵌套创建，即一个协程内部可以再创建一个协程。
4. 提供了超时管理，以及一套类 pthread 的接口，用于协程间通信。

关于 libco 的如何实现有栈协程的切换，co_resume、co_yield 是如何实现的。此部分内容已在 [云风 coroutine 协程库源码分析](http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/) 中进行了详细的剖析。各个协程库这里的实现大同小异，本文就不再重复讲述此部分内容了。

不过，libco 在协程的栈空间上有不一样的地方：

1. 共享栈是可选的，如果想要使用共享栈模式，则需要用户自行创建栈空间，在 co_create 时传递给 libco。(参数 `stCoRoutineAttr_t* attr`)
2. 支持协程使用独立的栈空间，不使用共享栈模式。(默认每个协程有 128k 的栈空间)
3. libco 默认是独立的栈空间，不使用共享栈。

除此之外，出于性能考虑，libco 不使用 ucontext 进行用户态上下文的切换，而是自行写了一套汇编来进行上下文切换。

另外，libco 利用 `co_create` 创建的协程, 需要自行调用 `co_release` 进行释放。这里和 coroutine 不太一样。

## 协程上下文切换性能更好

我们之前提到，云风的 coroutine 库使用 ucontext 来实现用户态的上下文切换，这也是实现协程的关键。

而 **libco 基于性能优化的考虑，没有使用 ucontext**，而是自行编写了一套汇编来处理上下文的切换, 具体代码在 [coctx_swap.S](https://github.com/Tencent/libco/blob/master/coctx_swap.S)。

libco 的上下文切换大体只保存和交换了两类东西：

1. 寄存器：函数参数类寄存器、函数返回值、数据存储类寄存器等。
2. 栈：rsp 栈顶指针

相比于 ucontext，缺少了浮点数上下文和 sigmask(信号屏蔽掩码)。具体可对比 [glibc 的相关源码](https://github.com/lattera/glibc/blob/master/sysdeps/unix/sysv/linux/i386/getcontext.S)。

- 取消 sigmask 是因为 sigmask 会引发一次 syscall，在性能上会所损耗。
- 取消浮点数上下文，主要是在服务端编程几乎用不到浮点数计算。

此外，libco 的上下文切换只支持 x86，不支持其他架构的 cpu，这是因为在服务端也几乎都是 x86 架构的，不用太考虑 CPU 的通用性。

据 [知乎网友的实验](https://www.zhihu.com/question/52193579/answer/156692295) 证明：libco 的上下文切换效率大致是 ucontext 的 3.6 倍。

总结来说，libco 牺牲了通用性，把运营环境中用不到的寄存器拷贝去掉，对代码进行了极致优化，以换取很好的性能。

## 协程在 IO 阻塞时可自动切换

我们希望的是，当协程中遇到阻塞 IO 的调用时，协程可以自行 yield 出去，等到调用结束可以再 resume 回来，这些流程无需用户关心。

**然而难点在于，** 对于自己代码中的阻塞类调用尚且容易改造，可以把它改成非阻塞 IO，然后框架内部进行 yield 和 resume。但是大量三方库也存在着阻塞 IO 调用，如知名的 mysqlclient 就是阻塞 IO。对于此类的 IO 调用，我们无法直接改造，不便于和我们现有的协程框架进行配合。

然而，libco 的协程不仅可以做到 IO 阻塞协程的自动切换，甚至包括三方库的阻塞 IO 调用都可以零改造的自动切换。

这是因为，libco 巧妙运用了 Linux 的 hook 技术，同时配合了 epoll 事件循环，完美的完成了阻塞 IO 的协程化改造。

所谓系统函数 hook，简单来说，就是可以替换原有的系统函数，例如 read、write 等，将其替换为自己的逻辑。libco 目前所有关于 hook 系统函数的代码都在 `co_hook_sys_call.cpp` 中可以看到。

在分析具体代码之前，有个点需要先注意下：**libco 的 hook 逻辑用于 client 行为的阻塞类 IO 调用**。

client 行为指的是，本地主动 connect 一个远程的服务，使用的时候一般先往 socket 中 write 数据，然后再 read 回包这种形式。

### read 函数的 hook 流程

我们以 read 函数为例，看下都做了什么：

```cpp
ssize_t read(int fd, void *buf, size_t nbyte)
{
	struct pollfd pf = {0};
	pf.fd = fd;
	pf.events = (POLLIN | POLLERR | POLLHUP);

	int pollret = poll(&pf,1,timeout);

	ssize_t readret = g_sys_read_func(fd,(char*)buf ,nbyte );
	return readret;
}
```

上述代码对原有代码进行了简略，只保留了最核心的 hook 逻辑。

注意：这里 poll 函数实际上也是被 hook 过的函数，在这个函数中，最终会交由 `co_poll_inner` 函数处理。

`co_poll_inner` 函数主要有三个作用：

1. 将 poll 的相关事件转换为 epoll 相关事件，并注册到当前线程的 epoll 中。
2. 注册超时事件，到当前的 epoll 中
3. 调用 co_yield_ct, 让出该协程。

可以看到，调用 poll 函数之后，相关事件注册到了 EventLoop 中后，该协程就 yield 走了。

那么，什么时候，协程会再 resume 回来呢？  
答案是：**当 epoll 相关事件触发或者超时触发时**，会再次 resume 该协程，处理接下来的流程。

协程 resume 之后，会接着处理 poll 之后的逻辑，也就是调用了 `g_sys_read_func`。这个函数就是真实的 linux 的 read 函数。

libco 使用 dlsym 函数获取了系统函数, 如下：

```cpp
typedef ssize_t (*read_pfn_t)(int fildes, void *buf, size_t nbyte);
static read_pfn_t g_sys_read_func = (read_pfn_t)dlsym(RTLD_NEXT,"read");
```

这个逻辑就非常巧妙了：

- 从内部来看，本质上是个异步流程，在 EventLoop 中注册相关事件，当事件触发时就执行接下来的处理函数。
- 从外部来看，调用方使用的时候函数行为和普通的阻塞函数基本一样，无需关系底层的注册事件、yield 等过程。

这个就是 libco 的巧妙之处了，通过 hook 系统函数的方式，几乎无感知的改造了阻塞 IO 调用。

此外，libco 也 hook 了系统的 socket 函数。在 libco 实现的 socket 函数中，会将 fd 变成非阻塞的 (O_NONBLOCK)。

那么，**为什么 libco 连 mysql_client 都可以一并协程化改造呢**？

这是因为 mysql_client 里面的具体网络 IO 实现，也是用的 Linux 的那些系统函数 connect、read、write 这些函数。  
所以，libco 只用 hook 十几个 socket 相关的 api，就可以将用到的三方库中的 IO 调用也一起协程化改造了。

### 超时处理

默认情况下，阻塞IO不会超时。但可以通过设置setsockopt设置socket的SO_RCVTIMEO和SO_SNDTIMEO来调整超时时间。

但在libco里面，默认的读写超时时间为1s。例如对于read函数来说:

```c++
unsigned int timeout =
	(lp->read_timeout.tv_sec * 1000) + (lp->read_timeout.tv_usec / 1000);

struct pollfd pf = {0};
pf.fd = fd;
pf.events = (POLLIN | POLLERR | POLLHUP);
poll(&pf, 1, timeout);

ssize_t ret = g_sys_read_func(fd, (char*)buf, nbyte);
```

这里的`lp->read_timeout`在socket函数中被设置为默认的1s。

同时，libco也hook了setsockopt函数，当设置SO_RCVTIMEO或SO_SNDTIMEO，会调整read_timeout和write_timeout的超时时间，使其与阻塞IO的行为保持一致。

```cpp
if (SO_RCVTIMEO == option_name) {
	memcpy(&lp->read_timeout, val, sizeof(*val));
} else if (SO_SNDTIMEO == option_name) {
	memcpy(&lp->write_timeout, val, sizeof(*val));
}
```

以上是libco对于读写超时的操作。但是对于阻塞IO的connect来说，libco中将其设置为了75s。75s是内核默认的connect超时时间。如下：

```cpp
int connect(int fd, const struct sockaddr* address, socklen_t address_len) {
  ...

  for (int i = 0; i < 3; i++)  // 25s * 3 = 75s
  {
    memset(&pf, 0, sizeof(pf));
    pf.fd = fd;
    pf.events = (POLLOUT | POLLERR | POLLHUP);

    pollret = poll(&pf, 1, 25000);

    if (1 == pollret) {
      break;
    }
  }
  ...
}
```

### stCoEpoll_t 结构体分析

libco 的事件循环同时支持 epoll 和 kqueue，libco 会在每个线程维护一个 `stCoEpoll_t` 对象。  
`stCoEpoll_t` 结构体中维护了事件循环需要的数据。

```cpp
struct stCoEpoll_t
{
	int iEpollFd;
	co_epoll_res *result;

	struct stTimeout_t *pTimeout;
	struct stTimeoutItemLink_t *pstTimeoutList;

	struct stTimeoutItemLink_t *pstActiveList;
};
```

1. iEpollFd：epoll 或者 kqueue 的 fd
2. result: 当前已触发的事件，给 epoll 或 kevent 用。如果是 epoll 的话，则是 epoll_wait 的已触发事件
3. pTimeout：时间轮定时管理器。记录了所有的定时事件
4. pstTimeoutList：本轮超时的事件
5. pstActiveList: 本轮触发的事件。

此外，libco 使用了时间轮来做超时管理，关于时间轮的原理分析网上比较多，这块也不是 libco 最核心的东西，就不在本文讨论了。

## 协程可以嵌套创建

libco 的协程可以嵌套创建，协程内部可以创建一个新的协程。这里其实没有什么黑科技，只不过云风 coroutine 中不能实现协程嵌套创建，所以在这里单独讲下。  
libco 使用了一个栈来维护协程调用过程。  
我们模拟下这个调用栈的运行过程, 如下图所示：  
![协程调用栈](https://www.cyhone.com/img/libco/co_process_stack.png)

图中绿色方块代表栈顶，同时也是当前正在运行的协程。

1. 当在主协程中 co_resume 到 A 协程时，当前运行的协程变更为 A，同时协程 A 入栈。
2. A 协程中 co_resume 到 B 协程，当前运行的协程变更为 B，同时协程 B 入栈。
3. 协程 B 中调用 co_yield_ct。协程 B 出栈，同时当前协程切换到协程 A。
4. 协程 A 中调用 co_yield_ct。协程 B 出栈，同时当前协程切换到主协程。

libco 的协程调用栈维护 stCoRoutineEnv_t 结构体中，如下：

```c
struct stCoRoutineEnv_t
{
	stCoRoutine_t *pCallStack[128];
	int iCallStackSize;
	stCoEpoll_t *pEpoll;
};
```

其中 pCallStack 即是协程的调用栈，从参数可以看出，libco 只能支持 128 层协程的嵌套调用，这个深度已经足够使用了。  
iCallStackSize 代表当前的调用深度。

## libco 的运营经验

libco 的负责人 leiffyli 在 purecpp 大会上分享了 [libco 的一些运营经验](http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf)，个人觉得里面的建议具体非常高的价值，这里直接引用过来。

> 协程栈大小有限，接入协程的服务谨慎使用栈空间；

libco 中默认每个协程的栈大小是 128k，虽然可以自定义每个协程栈的大小，但是其大小依然是有限资源。避免在栈上分配大内存对象 (如大数组等)。

> 池化使用，对系统中资源使用心中有数。随手创建与释放协程不是一个好的方式，有可能系统被过多的协程拖垮；

关于这点，libco 的示例 `example_echosvr.cpp` 就是一个池化使用的例子。

> 协程不适合运行 cpu 密集型任务。对于计算较重的服务，需要分离计算线程与网络线程，避免互相影响；

这是因为计算比较耗时的任务，会严重拖慢 EventLoop 的运行过程，导致事件响应和协程调度受到了严重影响。

> 过载保护。对于基于事件循环的协程调度框架，建议监控完成一次事件循环的时间，若此时间过长，会导致其它协程被延迟调度，需要与上层框架配合，减少新任务的调度；

## 总结

libco 巧妙的利用了 hook 技术，将协程的威力发挥的更加彻底，可以改良 C++ 的 RPC 框架异步化后的回调痛苦。整个库除了基本的协程函数，又加入类 pthread 的一些辅助功能，让协程的通信更加好用。

然而遗憾的是，libco 在开源方面做得并不是很好，后续 bug 维护和功能更新都不是很活跃。

但好消息是，据 leiffyli 的分享，目前有一些 libco 有一些实验中的特性，如事件回调、类 golang 的 channel 等，目前正在内部使用。相信后期也会同步到开源社区中。

## 参考

- [leiffyli：Libco 分享](http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf)
- [C/C++ 协程库 libco：微信怎样漂亮地完成异步化改造](https://www.infoq.cn/article/CplusStyleCorourtine-At-Wechat)
- [腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么? - 江哈莫夫斯基的回答](https://www.zhihu.com/question/52193579/answer/156692295)
- [libco 协程库上下文切换原理详解](https://zhuanlan.zhihu.com/p/27409164)
- [libco Github issue#41](https://github.com/Tencent/libco/issues/41)
- [man: dlsym](https://linux.die.net/man/3/dlsym)
- [man: read](http://man7.org/linux/man-pages/man2/read.2.html)

## Q
1. 随意改变ESP的值不会导致栈分配冲突么？是怎么解决的？ #TODO

	答： 运行时栈区不再由系统分配，而是由函数co_create_env 分配，co_create_env会分配最小 128kb最大8MB的内存空间作为一个co_routine的运行时栈空间。 每次co_routine调度时，系统（汇编部分coctx_swap方法）会保存当前co_routine的栈区到内存，并切换栈区基地址和栈顶地址指针到目标co_routine的基地址和栈顶地址（用过设置对应寄存器的值）。这样就不可能导致栈空间分配冲突。